{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining rows of data\n",
    "The dataset you'll be working with here relates to NYC Uber data. The original dataset has all the originating Uber pickup locations by time and latitude and longitude. For didactic purposes, you'll be working with a very small portion of the actual data.\n",
    "\n",
    "Three DataFrames have been pre-loaded: uber1, which contains data for April 2014, uber2, which contains data for May 2014, and uber3, which contains data for June 2014. Your job in this exercise is to concatenate these DataFrames together such that the resulting DataFrame has the data for all three months.\n",
    "\n",
    "Begin by exploring the structure of these three DataFrames in the IPython Shell using methods such as .head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "uber = pd.read_csv('nyc_uber_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber1 = uber[uber['Date/Time'].str.contains(\"4/1/2014\")]\n",
    "uber2 = uber[uber['Date/Time'].str.contains(\"5/1/2014\")]\n",
    "uber3 = uber[uber['Date/Time'].str.contains(\"6/1/2014\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 5)\n",
      "   Unnamed: 0         Date/Time      Lat      Lon    Base\n",
      "0           0  4/1/2014 0:11:00  40.7690 -73.9549  B02512\n",
      "1           1  4/1/2014 0:17:00  40.7267 -74.0345  B02512\n",
      "2           2  4/1/2014 0:21:00  40.7316 -73.9873  B02512\n",
      "3           3  4/1/2014 0:28:00  40.7588 -73.9776  B02512\n",
      "4           4  4/1/2014 0:33:00  40.7594 -73.9722  B02512\n"
     ]
    }
   ],
   "source": [
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1, uber2, uber3])\n",
    "\n",
    "# Print the shape of row_concat\n",
    "print(row_concat.shape)\n",
    "\n",
    "# Print the head of row_concat\n",
    "print(row_concat.head())\n",
    "\n",
    "# Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "# ebola_tidy = pd.concat([ebola_melt,status_country],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globbing\n",
    "In order to concatenate DataFrames:\n",
    "\n",
    "- They must be in a list  \n",
    "- can individually load if there are a few datasets  \n",
    "When there are too many files to concatenate, we can use the glob function to find files based on a pattern. Globbing is simple way for python to do pattern matching for file names. We can use various wildcards like * and ? to specify a file name pattern we are looking for.\n",
    "\n",
    "A wildcard is a symbol that will match any arbitrary number of characters.\n",
    "\n",
    "- *match any string. e.g. *.csv matches any csv files  \n",
    "- ? only allows us to match one character e.g. file_?.csv matches file_a.csv, file_b.csv and so on.  \n",
    "Then globbing will return a list of file names, which can be used to load files into separate DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "csv_files = glob.glob('*.csv') #returns a list of file names\n",
    "list_data = []\n",
    "for filename in csv_files:\n",
    "\tdata = pd.read_csv(filename)\n",
    "\tlist_data.append(data)\n",
    "\t#returns a list of dataframes\n",
    "pd.concat(list_data) #concat the list of df into a single df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-to-1 data merge\n",
    "Merging data allows you to combine disparate datasets into a single dataset to do more complex analysis.\n",
    "\n",
    "Here, you'll be using survey data that contains readings that William Dyer, Frank Pabodie, and Valentina Roerich took in the late 1920s and 1930s while they were on an expedition towards Antarctica. The dataset was taken from a sqlite database from the Software Carpentry SQL lesson.\n",
    "\n",
    "Two DataFrames have been pre-loaded: site and visited. Explore them in the IPython Shell and take note of their structure and column names. Your task is to perform a 1-to-1 merge of these two DataFrames using the 'name' column of site and the 'site' column of visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print o2o\n",
    "print(o2o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of merges\n",
    "\n",
    "- one-one-one merge: There is no duplicate values in the key column\n",
    "- one-to-many/many-to-one merge: duplicate values in the key column\n",
    "- many-to-many: when both DataFrames do not have unique keys for a merge. What happens here is that for each duplicated key, every pairwise combination will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
