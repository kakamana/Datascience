{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Loss function\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-01-18\"\n",
    "categories: [python, datacamp, logistic regression, machine learning, SVM ]\n",
    "image: \"lossFunction.jpg\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss function\n",
    "\n",
    "We will discover the conceptual framework behind logistic regression and SVMs. This will let us delve deeper into the inner workings of these models.\n",
    "\n",
    "This **Loss function** is part of [Datacamp course: Linear Classifiers in Python](https://app.datacamp.com/learn/courses/linear-classifiers-in-python)\n",
    "\n",
    "This is my learning experience of data science through DataCamp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear classifier prediction\n",
    "\n",
    "* raw model output = coefficient * feature + intercept\n",
    "* Linear classifier prediction: compute raw model output, check the sign\n",
    "    * if +ve predict one class\n",
    "    * if -ve predict another class\n",
    "* This is same for logistic regression and linear SVM\n",
    "    * fit is different but predict is same"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Changing the model coefficients\n",
    "When you call `fit` with scikit-learn, the logistic regression coefficients are automatically learned from your dataset. In this exercise you will explore how the decision boundary is represented by the coefficients. To do so, you will change the coefficients manually (instead of with `fit`), and visualize the resulting classifiers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#hide\n",
    "X = np.array([[ 1.78862847,  0.43650985],\n",
    "       [ 0.09649747, -1.8634927 ],\n",
    "       [-0.2773882 , -0.35475898],\n",
    "       [-3.08274148,  2.37299932],\n",
    "       [-3.04381817,  2.52278197],\n",
    "       [-1.31386475,  0.88462238],\n",
    "       [-2.11868196,  4.70957306],\n",
    "       [-2.94996636,  2.59532259],\n",
    "       [-3.54535995,  1.45352268],\n",
    "       [ 0.98236743, -1.10106763],\n",
    "       [-1.18504653, -0.2056499 ],\n",
    "       [-1.51385164,  3.23671627],\n",
    "       [-4.02378514,  2.2870068 ],\n",
    "       [ 0.62524497, -0.16051336],\n",
    "       [-3.76883635,  2.76996928],\n",
    "       [ 0.74505627,  1.97611078],\n",
    "       [-1.24412333, -0.62641691],\n",
    "       [-0.80376609, -2.41908317],\n",
    "       [-0.92379202, -1.02387576],\n",
    "       [ 1.12397796, -0.13191423]])\n",
    "\n",
    "y = np.array([-1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1,  1,  1, -1,  1, -1, -1,\n",
    "       -1, -1, -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02, lims=None):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        x: data to base x-axis meshgrid on\n",
    "        y: data to base y-axis meshgrid on\n",
    "        h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        xx, yy : ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    if lims is None:\n",
    "        x_min, x_max = x.min() - 1, x.max() + 1\n",
    "        y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    else:\n",
    "        x_min, x_max, y_min, y_max = lims\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, proba=False, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        ax: matplotlib axes object\n",
    "        clf: a classifier\n",
    "        xx: meshgrid ndarray\n",
    "        yy: meshgrid ndarray\n",
    "        params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    if proba:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,-1]\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        out = ax.imshow(Z,extent=(np.min(xx), np.max(xx), np.min(yy), np.max(yy)),\n",
    "                        origin='lower', vmin=0, vmax=1, **params)\n",
    "        ax.contour(xx, yy, Z, levels=[0.5])\n",
    "    else:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "def plot_classifier(X, y, clf, ax=None, ticks=False, proba=False, lims=None):\n",
    "    # assumes classifier \"clf\" is already fit\n",
    "    X0, X1 = X[:, 0], X[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1, lims=lims)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "        show = True\n",
    "    else:\n",
    "        show = False\n",
    "\n",
    "    # can abstract some of this into a higher-level function for learners to call\n",
    "    cs = plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8, proba=proba)\n",
    "    if proba:\n",
    "        cbar = plt.colorbar(cs)\n",
    "        cbar.ax.set_ylabel('probability of red $\\Delta$ class', fontsize=20, rotation=270, labelpad=30)\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "        #ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=30, edgecolors=\\'k\\', linewidth=1)\n",
    "    labels = np.unique(y)\n",
    "    if len(labels) == 2:\n",
    "        ax.scatter(X0[y==labels[0]], X1[y==labels[0]], cmap=plt.cm.coolwarm,\n",
    "                   s=60, c='b', marker='o', edgecolors='k')\n",
    "        ax.scatter(X0[y==labels[1]], X1[y==labels[1]], cmap=plt.cm.coolwarm,\n",
    "                   s=60, c='r', marker='^', edgecolors='k')\n",
    "    else:\n",
    "        ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=50, edgecolors='k', linewidth=1)\n",
    "\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    #     ax.set_xlabel(data.feature_names[0])\n",
    "    #     ax.set_ylabel(data.feature_names[1])\n",
    "    if ticks:\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        #     ax.set_title(title)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return ax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 3\n"
     ]
    }
   ],
   "source": [
    "# Set the coefficients\n",
    "model.coef_ = np.array([[0,1]])\n",
    "model.intercept_ = np.array([0])\n",
    "\n",
    "# Plot the data and decision boundary\n",
    "plot_classifier(X,y,model)\n",
    "\n",
    "# Print the number of errors\n",
    "num_err = np.sum(y != model.predict(X))\n",
    "print(\"Number of errors:\", num_err)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 0\n",
      "\n",
      "As you can see, the coefficients determine the slope of the boundary and the intercept shifts it.\n"
     ]
    }
   ],
   "source": [
    "# Set the coefficients\n",
    "model.coef_ = np.array([[-1,1]])\n",
    "model.intercept_ = np.array([-3])\n",
    "\n",
    "# Plot the data and decision boundary\n",
    "plot_classifier(X,y,model)\n",
    "\n",
    "# Print the number of errors\n",
    "num_err = np.sum(y != model.predict(X))\n",
    "print(\"Number of errors:\", num_err)\n",
    "print(\"\\nAs you can see, the coefficients determine the slope of the boundary and the intercept shifts it.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What is a loss function?\n",
    "- Least squares: the squared loss\n",
    "    - scikit-learn's `LinearRegression` minimizes a loss:\n",
    "    $$ \\sum_{i=1}^{n}(\\text{true ith target value - predicted ith target value})^2 $$\n",
    "    - Minimization is with respect to coefficients or parameters of the model.\n",
    "- Classification errors: the 0-1 loss\n",
    "    - Squared loss not appropriate for classification problems\n",
    "    - A natrual loss for classification problem is the number of errors\n",
    "    - This is the **0-1 loss**: it's 0 for a correct prediction and 1 for an incorrect prediction\n",
    "    - But this loss is hard to minimize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Minimizing a loss function\n",
    "In this exercise you'll implement linear regression \"from scratch\" using `scipy.optimize.minimize`.\n",
    "\n",
    "We'll train a model on the Boston housing price data set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X = pd.read_csv('dataset/boston_X.csv').to_numpy()\n",
    "y = pd.read_csv('dataset/boston_y.csv').to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.16299653e-02  4.86753446e-02 -3.77679680e-03  2.85637065e+00\n",
      " -2.88057050e+00  5.92521235e+00 -7.22477068e-03 -9.67992962e-01\n",
      "  1.70449044e-01 -9.38970634e-03 -3.92422954e-01  1.49831080e-02\n",
      " -4.16973126e-01]\n",
      "[[-9.16297843e-02  4.86751203e-02 -3.77930006e-03  2.85636751e+00\n",
      "  -2.88077933e+00  5.92521432e+00 -7.22447929e-03 -9.67995240e-01\n",
      "   1.70443393e-01 -9.38925373e-03 -3.92425680e-01  1.49832102e-02\n",
      "  -4.16972624e-01]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# The squared error, summed overt training examples\n",
    "def my_loss(w):\n",
    "    s = 0\n",
    "    for i in range(y.size):\n",
    "        # Get the true and predicted target values for example 'i'\n",
    "        y_i_true = y[i]\n",
    "        y_i_pred = w@X[i]\n",
    "        s = s + (y_i_true - y_i_pred) ** 2\n",
    "    return s\n",
    "\n",
    "# Returns the w that makes my_loss(w) smallest\n",
    "w_fit = minimize(my_loss, X[0]).x\n",
    "print(w_fit)\n",
    "\n",
    "# Compare with scikit-learn's LinearRegression coefficients\n",
    "lr = LinearRegression(fit_intercept=False).fit(X, y)\n",
    "print(lr.coef_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](Images/0-1 loss diagram.jpg)\n",
    "![](Images/linear regression loss diagram.jpg)\n",
    "![](Images/logistic loss diagram.jpg)\n",
    "![](Images/Hinge loss diagram.jpg)\n",
    "![](Images/logistic hinge loss diagram.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}