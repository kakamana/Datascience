{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "title: \"Feature Selection I - Selecting for Feature Information\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "author: \"kakamana\"\n",
    "date: \"2023-01-22\"\n",
    "categories: [python, datacamp, feature engineering, machine learning, dimension reduction]\n",
    "image: \"samplingIntroduction.jpg\"\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection I - Selecting for Feature Information\n",
    "\n",
    "As we progress through feature selection, we'll learn how dimensionality reduction can help us overcome its curse. We'll be introduced to a variety of techniques for identifying and removing features that don't add much value to your data. Either because they have little variance, too many missing values, or because they are strongly correlated with other features.\n",
    "\n",
    "This **Feature Selection I - Selecting for Feature Information** is part of [Datacamp course: Hypothesis Testing in Python](https://app.datacamp.com/learn/courses/hypothesis-testing-in-python)\n",
    "\n",
    "This is my learning experience of data science through DataCamp"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
